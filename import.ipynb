{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1828a4c5-84d9-4d19-b4c4-01d56bf7d3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "06-DocumentLoader\n"
     ]
    }
   ],
   "source": [
    "# 기본 세팅\n",
    "import os; import pandas as pd; import numpy as np; import streamlit as st\n",
    "import matplotlib as plt; import seaborn as sns; import plotly\n",
    "import re; import requests; from bs4 import BeautifulSoup\n",
    "from dotenv import load_dotenv; load_dotenv()\n",
    "from langchain_teddynote import logging   # 랭스미스 로그 추적   \n",
    "logging.langsmith(\"19-Streamlit\")         # 프로젝트 이름,   set_enable=False : 로그 추적 끄기\n",
    "from langchain_teddynote.messages import stream_response     # 스트리밍\n",
    "import warnings; warnings.filterwarnings(\"ignore\")           # 경고 메시지 무시\n",
    "\n",
    "# LLM models\n",
    "from langchain_openai import ChatOpenAI                      # 기본 LLM\n",
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o-mini\")    # 기본 LLM 객체를 정의\n",
    "from langchain_teddynote.models import MultiModal            # 멀티모달(이미지 인식) \n",
    "\n",
    "# LCEL(chain 문법)\n",
    "from langchain_core.output_parsers import StrOutputParser    # 문자열 출력 파서\n",
    "from langchain_core.runnables import RunnablePassthrough     # key값 없이 invoke에 값만 넣어줘서 편리.\n",
    "from langchain_core.runnables import Runnable, RunnableLambda  # 사용자 함수 맵핑\n",
    "from operator import itemgetter         # invoke에 딕셔너리로 여러 값을 주면 itemgetter가 값들만 추출\n",
    "\n",
    "# 프롬프트\n",
    "from langchain_core.prompts import PromptTemplate            # 프롬프트 템플릿\n",
    "from langchain_core.prompts import ChatPromptTemplate        # AI와 대화용 프롬프트 템플릿\n",
    "from langchain_core.prompts import load_prompt               # 프롬프트 파일에서 가져오기\n",
    "from langchain_core.prompts import MessagesPlaceholder       # 임시 공간_대화 기록이 쌓이게 됨\n",
    "from langchain_core.prompts.few_shot import FewShotPromptTemplate   # 퓨샷 프롬프트 템플릿\n",
    "\n",
    "# 예제 선택기\n",
    "from langchain_core.example_selectors import (               # 질문과 유사도가 높은 예제를 선택해서 넣어주기.\n",
    "    MaxMarginalRelevanceExampleSelector,                     # MMR => \n",
    "    SemanticSimilarityExampleSelector,                       # 시맨틱 유사도(cosine similarity) 기반 예제 선택\n",
    ")\n",
    "\n",
    "# RAG1. 로드\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "# RAG2. 청킹\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# RAG3. 임베딩\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# RAG4. 벡터DB\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.vectorstores import FAISS\n",
    "import faiss\n",
    "\n",
    "# 출력 파서\n",
    "from langchain_core.output_parsers import PydanticOutputParser   # 답변 형식을 원하는대로 정의(ex. JSON)\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.output_parsers.openai_tools import JsonOutputToolsParser  # tool 파서\n",
    "from typing import List, Dict, Union, Annotated\n",
    "\n",
    "# 부가 기능\n",
    "from langchain_community.utilities import SerpAPIWrapper         # 검색기 SerpAPI\n",
    "from langchain_teddynote.translate import Translator             # 번역기\n",
    "from datasets import Dataset                                     # RAG 관련 dataset\n",
    "\n",
    "# 메모리\n",
    "from langchain.memory import ConversationBufferMemory            # 대화 내용 저장\n",
    "from langchain.chains import ConversationChain                   # chain 에서 대화내용 저장\n",
    "from langchain.docstore import InMemoryDocstore                  # 벡터스토어 요소\n",
    "from langchain.memory import VectorStoreRetrieverMemory          # VectorStoreRetrieverMemory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory    # 저장된 대화 기록을 가져오는 체인 구성\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory  # 대화 저장소\n",
    "\n",
    "# DB\n",
    "from langchain_community.chat_message_histories import SQLChatMessageHistory   # SQL\n",
    "\n",
    "# 도큐먼트 로더\n",
    "from langchain_core.documents import Document\n",
    "from langchain.document_loaders import PyPDFLoader, PDFPlumberLoader, PyMuPDFLoader   # PDF 로더들\n",
    "from langchain_community.document_loaders import UnstructuredPDFLoader\n",
    "from langchain_community.document_loaders import PyPDFium2Loader\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader      # PDF 디렉토리 로더\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader      # CSV 로더\n",
    "from langchain_community.document_loaders import DirectoryLoader           # 디렉토리 로더\n",
    "from langchain_community.document_loaders import PythonLoader              # 파이썬 로더\n",
    "\n",
    "# RAG(LLM) 평가\n",
    "import langchain\n",
    "import ragas\n",
    "from ragas.testset.generator import TestsetGenerator         # 질문 생성\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context, conditional  # 질문 형식 : 간단 질문, 추론, 여러 문맥에서 찾는, 조건부 질문\n",
    "from ragas.llms import LangchainLLMWrapper                                 \n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from ragas.testset.extractor import KeyphraseExtractor       # 주요 구문 추출기\n",
    "from ragas.testset.docstore import InMemoryDocumentStore     # 문서 저장, 관리\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (   # <ragas 평가항목 4가지>\n",
    "    context_recall,           # 생성된 답변과 검색된 context의 일치도\n",
    "    context_precision,        # 얼마나 관련성 있는 문서가 상위에 배치되었나\n",
    "    answer_relevancy,         # 생성된 답변이 질문에 얼마나 유사한지 \n",
    "    faithfulness,             # 생성된 답변의 사실적 일관성(컨텍스트와 비교)\n",
    ")\n",
    "\n",
    "# Tools(Agent)\n",
    "from langchain_experimental.tools import PythonREPLTool, PythonAstREPLTool  # PythonREPL\n",
    "from langchain_experimental.utilities import PythonREPL      \n",
    "from langchain_community.tools.tavily_search import TavilySearchResults  # Tavily 검색 API\n",
    "from langchain_teddynote.tools import GoogleNews                         # 구글 뉴스기사 검색\n",
    "from langchain_community.utilities.dalle_image_generator import DallEAPIWrapper  # Dall-E API\n",
    "from IPython.display import Image\n",
    "from langchain.tools import tool                                         # 사용자 정의 tools\n",
    "from langchain.agents import create_tool_calling_agent       # LLM Binding Tools\n",
    "from langchain.agents import AgentExecutor                   # AgentExecutor\n",
    "from langchain_teddynote.messages import AgentStreamParser   # Agent 중간단계 스트리밍\n",
    "from langchain.tools.retriever import create_retriever_tool  # RAG 도구화\n",
    "\n",
    "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent # Pandas\n",
    "from langchain.agents.agent_types import AgentType           # Agent Type\n",
    "from langchain_teddynote.messages import AgentCallbacks      # Agent callback 함수\n",
    "from langchain_community.agent_toolkits import FileManagementToolkit  # 파일 관리 Toolkit\n",
    "\n",
    "# Streamlit\n",
    "import streamlit as st                                       # Streamlit\n",
    "from langchain_core.messages.chat import ChatMessage         # Streamlit에서 ChatMessage 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eec4f2f-99f3-45d4-81a2-0b1a79d98709",
   "metadata": {},
   "source": [
    "# RAG chain 구성(기본 구조)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7920fb9-0406-4da5-90d2-b50d0dbdd4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG 사전준비 4단계(로드-청킹-임베딩-벡터DB)\n",
    "\n",
    "# 단계 1: 문서 로드(Load Documents)\n",
    "loader = PyMuPDFLoader(\"data/SPRI_AI_Brief_2023년12월호_F.pdf\")\n",
    "docs = loader.load()    # docs : pdf 페이지 단위로 쪼개짐 \n",
    "\n",
    "# # 페이지 내용 출력\n",
    "# print(docs[10].page_content)\n",
    "# docs[10].__dict__\n",
    "\n",
    "# 단계 2: 청킹(Chunking), 문서 분할(Split Documents)\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "split_documents = text_splitter.split_documents(docs)\n",
    "# print(f\"분할된 청크의수: {len(split_documents)}\")\n",
    "\n",
    "# 단계 3: 임베딩(Embedding) 생성\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# 단계 4: DB 생성(Create DB) 및 저장\n",
    "# 벡터스토어를 생성합니다.\n",
    "vectorstore = FAISS.from_documents(documents=split_documents, embedding=embeddings)\n",
    "# for doc in vectorstore.similarity_search(\"구글\"):\n",
    "#     print(doc.page_content)\n",
    "\n",
    "# RAG 실행(Run-time) 4단계\n",
    "\n",
    "# 단계 5: 검색기(Retriever) 생성\n",
    "# 문서에 포함되어 있는 정보를 검색하고 생성합니다.\n",
    "retriever = vectorstore.as_retriever(k=4)\n",
    "# # 검색기에 쿼리를 날려 유사한 chunk 검색 결과를 확인합니다.\n",
    "# retriever.invoke(\"삼성전자가 자체 개발한 AI 의 이름은?\")\n",
    "\n",
    "# 단계 6: 프롬프트 생성(Create Prompt)\n",
    "# 프롬프트를 생성합니다.\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Answer in Korean. You must include `page` number in you answer.\n",
    "\n",
    "# Context: \n",
    "{context}\n",
    "\n",
    "# Question:\n",
    "{question}\n",
    "\n",
    "# Answer:\"\"\"\n",
    ")\n",
    "\n",
    "# 단계 7: 언어모델(LLM) 생성\n",
    "# 모델(LLM) 을 생성합니다.\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# 단계 8: 체인(Chain) 생성\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4b4d204-b39e-4de8-b508-1522c3db9660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삼성전자가 자체 개발한 AI의 이름은 '삼성 가우스'입니다. (page 12)\n"
     ]
    }
   ],
   "source": [
    "# 체인 실행(Run Chain)\n",
    "# 문서에 대한 질의를 입력하고, 답변을 출력합니다.\n",
    "question = \"삼성전자가 자체 개발한 AI 의 이름은?\"\n",
    "response = chain.invoke(question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed361b6-9a5c-4048-bdb7-475711306075",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c6b18fa-8f50-4ff3-96d2-e08f5f7a6290",
   "metadata": {},
   "source": [
    "## Agent 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002c73f4-a099-4236-97b1-0e25f2cd4cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 작업 디렉토리 경로 설정\n",
    "working_directory = \"tmp\"\n",
    "\n",
    "# 파일 관리 도구 생성(파일 쓰기, 읽기, 디렉토리 목록 조회)\n",
    "file_tools = FileManagementToolkit(\n",
    "    root_dir=str(working_directory),\n",
    "    selected_tools=[\"write_file\", \"read_file\", \"list_directory\"],\n",
    ").get_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f2853e-5adb-43e6-b1dd-6f3a7c889164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# session_id 를 저장할 딕셔너리 생성\n",
    "store = {}\n",
    "\n",
    "# 프롬프트 생성\n",
    "# 프롬프트는 에이전트에게 모델이 수행할 작업을 설명하는 텍스트를 제공합니다. (도구의 이름과 역할을 입력)\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. \"\n",
    "            \"You are a professional researcher. \"\n",
    "            \"You can use the pdf_search tool to search for information in the PDF file. \"\n",
    "            \"You can find further information by using search tool. \"\n",
    "            \"You can use image generation tool to generate image from text. \"\n",
    "            \"Finally, you can use file management tool to save your research result into files.\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# LLM 생성\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# Agent 생성\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "\n",
    "# AgentExecutor 생성\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=False,\n",
    "    handle_parsing_errors=True,\n",
    ")\n",
    "\n",
    "# session_id 를 기반으로 세션 기록을 가져오는 함수\n",
    "def get_session_history(session_ids):\n",
    "    if session_ids not in store:                      # session_id 가 store에 없는 경우\n",
    "        store[session_ids] = ChatMessageHistory()     # 새로운 ChatMessageHistory 객체를 생성하여 store에 저장\n",
    "    return store[session_ids]                         # 해당 세션 ID에 대한 세션 기록 반환\n",
    "\n",
    "# 채팅 메시지 기록이 추가된 에이전트를 생성합니다.\n",
    "agent_with_chat_history = RunnableWithMessageHistory(\n",
    "    agent_executor,                       # agent_executor\n",
    "    get_session_history,                  # 대화 session_id\n",
    "    input_messages_key=\"input\",           # 프롬프트의 질문이 입력되는 key: \"input\"\n",
    "    history_messages_key=\"chat_history\",  # 프롬프트의 메시지가 입력되는 key: \"chat_history\"\n",
    ")\n",
    "\n",
    "agent_stream_parser = AgentStreamParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf3543f-b3a0-44c7-9840-e8d3bba914a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfffb3d-37c4-4d18-93e8-6dc8fa42bb85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f5998c-1f48-40dc-9922-42b61da6b531",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29142cf9-c647-4f98-bc1b-10875ac17e12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_td",
   "language": "python",
   "name": "langchain_td"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
